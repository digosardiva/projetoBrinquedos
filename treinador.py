# treinador_excel.py
import json
from pathlib import Path

import joblib
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, classification_report,
                             confusion_matrix)
from sklearn.model_selection import train_test_split

# Configura√ß√µes / caminhos
INPUT_XLSX = Path("treinamento_gerado.xlsx")
SHEET_TREINO = "treinamento"
ARTIFACT_DIR = Path("model_artifacts")
ARTIFACT_DIR.mkdir(exist_ok=True)
MODEL_OUT = ARTIFACT_DIR / "modelo_cabem.pkl"
METADATA_OUT = ARTIFACT_DIR / "metadata.json"
SAVE_CONF_MATRIX = True  # alterar para False para n√£o salvar figura

# 1) Carregar dados do Excel
print("üì¶ Carregando", INPUT_XLSX, "sheet:", SHEET_TREINO)
if not INPUT_XLSX.exists():
    raise FileNotFoundError(f"{INPUT_XLSX} n√£o encontrado. Gere o Excel primeiro.")

df = pd.read_excel(INPUT_XLSX, sheet_name=SHEET_TREINO)
print("‚úÖ Sheet carregada. Linhas:", len(df))

# 2) Normalizar nomes das colunas esperadas
df.columns = [c.strip() for c in df.columns]
expected_cols = ['produto', 'c_brin', 'l_brin', 'a_brin', 'area_brin',
                 'c_gar', 'l_gar', 'a_gar', 'area_gar', 'cabe_area',
                 'cabe_dim', 'label']
# aceitar se tiver pelo menos as colunas essenciais
essenciais = ['produto', 'c_brin', 'l_brin', 'a_brin', 'c_gar', 'l_gar', 'a_gar', 'label']
for c in essenciais:
    if c not in df.columns:
        raise ValueError(f"Coluna essencial ausente no sheet '{SHEET_TREINO}': {c}")

# 3) Limpeza m√≠nima e tipos
df['produto'] = df['produto'].astype(str).str.strip()
for col in ['c_brin', 'l_brin', 'a_brin', 'area_brin', 'c_gar', 'l_gar', 'a_gar', 'area_gar']:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')
# remover linhas com NaN nas colunas essenciais
df = df.dropna(subset=['produto', 'c_brin', 'l_brin', 'a_brin', 'c_gar', 'l_gar', 'a_gar', 'label'])
df['label'] = df['label'].astype(int)

print("üìä Dataset ap√≥s limpeza:", df.shape)

# 4) One-hot encode do produto (mantemos todas as categorias encontradas)
df_encoded = pd.get_dummies(df, columns=['produto'], prefix='produto', drop_first=False)

# 5) Definir features e target
# incluir tamb√©m area_brin e area_gar se presentes
feature_cols = ['c_brin', 'l_brin', 'a_brin', 'c_gar', 'l_gar', 'a_gar']
if 'area_brin' in df_encoded.columns:
    feature_cols.append('area_brin')
if 'area_gar' in df_encoded.columns:
    feature_cols.append('area_gar')

# adicionar as colunas one-hot de produto
produto_cols = [c for c in df_encoded.columns if c.startswith('produto_')]
feature_cols += produto_cols

X = df_encoded[feature_cols]
y = df_encoded['label']

print("üîé Features usadas (exemplo):", feature_cols[:8], " ... total:", len(feature_cols))
print("Classes no target:", y.value_counts().to_dict())

# 6) Split treino/teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y if len(y.unique()) > 1 else None
)

# 7) Treinar modelo
print("üõ†Ô∏è Treinando RandomForest...")
model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)
model.fit(X_train, y_train)

# 8) Avaliar
y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print(f"\nüéØ Acur√°cia: {acc:.4f}\n")
print("üìã Relat√≥rio de classifica√ß√£o:")
print(classification_report(y_test, y_pred, zero_division=0))

# Matriz de confus√£o
# 8) Avaliar resultados e gerar dashboards
y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print(f"\nüéØ Acur√°cia: {acc:.4f}\n")
print("üìã Relat√≥rio de classifica√ß√£o:")
print(classification_report(y_test, y_pred, zero_division=0))

cm = confusion_matrix(y_test, y_pred)
print("Matriz de confus√£o:\n", cm)

# === Dashboards ===
print("\nüìà Gerando dashboards de desempenho...")

# --- 1Ô∏è‚É£ Matriz de confus√£o ---
plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Matriz de Confus√£o")
plt.xlabel("Previsto")
plt.ylabel("Real")
plt.tight_layout()
plt.savefig(ARTIFACT_DIR / "dashboard_confusion_matrix.png")
plt.close()

# --- 2Ô∏è‚É£ Import√¢ncia das features ---
feat_imp = pd.Series(model.feature_importances_, index=feature_cols).sort_values(ascending=False)
plt.figure(figsize=(10, 5))
sns.barplot(x=feat_imp.values[:10], y=feat_imp.index[:10], palette="viridis")
plt.title("Top 10 Features Importantes")
plt.xlabel("Import√¢ncia")
plt.ylabel("Feature")
plt.tight_layout()
plt.savefig(ARTIFACT_DIR / "dashboard_feature_importance.png")
plt.close()

# --- 3Ô∏è‚É£ Distribui√ß√£o do target original ---
plt.figure(figsize=(4, 4))
sns.countplot(x='label', data=df, palette="coolwarm")
plt.title("Distribui√ß√£o das Classes (label)")
plt.xlabel("Classe")
plt.ylabel("Contagem")
plt.tight_layout()
plt.savefig(ARTIFACT_DIR / "dashboard_target_distribution.png")
plt.close()

# --- 4Ô∏è‚É£ Correla√ß√£o entre medidas principais ---
plt.figure(figsize=(8, 6))
sns.heatmap(df[['c_brin', 'l_brin', 'a_brin', 'c_gar', 'l_gar', 'a_gar']].corr(), 
            annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correla√ß√£o entre Dimens√µes")
plt.tight_layout()
plt.savefig(ARTIFACT_DIR / "dashboard_correlacao_dimensoes.png")
plt.close()

# --- 5Ô∏è‚É£ Comparativo: √°rea do brinquedo x garagem ---
if 'area_brin' in df.columns and 'area_gar' in df.columns:
    plt.figure(figsize=(6, 5))
    sns.scatterplot(data=df, x='area_brin', y='area_gar', hue='label', palette="viridis", alpha=0.7)
    plt.title("Rela√ß√£o √Årea Brinquedo x Garagem")
    plt.xlabel("√Årea Brinquedo")
    plt.ylabel("√Årea Garagem")
    plt.tight_layout()
    plt.savefig(ARTIFACT_DIR / "dashboard_area_relacao.png")
    plt.close()

print("‚úÖ Dashboards gerados e salvos em", ARTIFACT_DIR)

# 9) Salvar modelo e metadata 
joblib.dump(model, MODEL_OUT)
metadata = {
    "feature_columns": feature_cols,
    "produto_columns": produto_cols,
    "n_samples": int(len(df)),
    "random_state": 42
}
with open(METADATA_OUT, "w", encoding="utf-8") as f:
    json.dump(metadata, f, ensure_ascii=False, indent=2)

print(f"\n‚úÖ Modelo salvo em {MODEL_OUT}")
print(f"‚úÖ Metadata salva em {METADATA_OUT}")